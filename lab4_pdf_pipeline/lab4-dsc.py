import os
import glob
from typing import List, Dict, Any, Optional, Tuple
import time
import random
import numpy as np
import pyarrow as pa

import ssl

ssl._create_default_https_context = ssl._create_stdlib_context

from tiktoken import get_encoding

# –ù–µ–æ–±—Ö–æ–¥–∏–º–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ 
import transformers

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–∑ docling
from docling.chunking import HybridChunker
from docling.document_converter import DocumentConverter

# –î–ª—è —Ä–∞–±–æ—Ç—ã —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ –∏ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î
import lancedb
from lancedb.embeddings import get_registry
from lancedb.pydantic import LanceModel, Vector

# –î–ª—è —Ä–∞–±–æ—Ç—ã —Å OpenAI
from openai import OpenAI
import openai

# –î–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
from dotenv import load_dotenv

from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

import ipywidgets as widgets
from IPython.display import display, clear_output, Markdown, HTML

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv()

# –†–µ–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å OpenAI
from transformers.tokenization_utils_base import PreTrainedTokenizerBase

# –°–æ–∑–¥–∞–µ–º –∫–ª–∞—Å—Å-–æ–±–µ—Ä—Ç–∫—É –¥–ª—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ OpenAI, —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Å –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º HybridChunker
class OpenAITokenizerWrapper(PreTrainedTokenizerBase):
    """–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ OpenAI."""

    def __init__(
        self, model_name: str = "cl100k_base", max_length: int = 8191, **kwargs
    ):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞.

        Args:
            model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ OpenAI –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            max_length: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        """
        super().__init__(model_max_length=max_length, **kwargs)
        self.tokenizer = get_encoding(model_name)
        self._vocab_size = self.tokenizer.max_token_value

    def tokenize(self, text: str, **kwargs) -> List[str]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π HybridChunker."""
        return [str(t) for t in self.tokenizer.encode(text)]

    def _tokenize(self, text: str) -> List[str]:
        return self.tokenize(text)

    def _convert_token_to_id(self, token: str) -> int:
        return int(token)

    def _convert_id_to_token(self, index: int) -> str:
        return str(index)

    def get_vocab(self) -> Dict[str, int]:
        return dict(enumerate(range(self.vocab_size)))

    @property
    def vocab_size(self) -> int:
        return self._vocab_size

    def save_vocabulary(self, *args) -> Tuple[str]:
        return ()

    @classmethod
    def from_pretrained(cls, *args, **kwargs):
        """–ö–ª–∞—Å—Å–æ–≤—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É HuggingFace."""
        return cls()
    
client = OpenAI(api_key="")

# –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –¥–ª—è OpenAI
tokenizer = OpenAITokenizerWrapper()

# –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏ text-embedding-3-large
MAX_TOKENS = 8191

def convert_pdf_to_document(pdf_path):
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç PDF –≤ —Ñ–æ—Ä–º–∞—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ docling.
    
    Args:
        pdf_path: –ø—É—Ç—å –∫ PDF-—Ñ–∞–π–ª—É
        
    Returns:
        –û–±—ä–µ–∫—Ç docling —Å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–º
    """
    converter = DocumentConverter()
    # # –î–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –Ω—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å file:// –ø—Ä–æ—Ç–æ–∫–æ–ª
    if not pdf_path.startswith('http'):
         pdf_path = f"{os.path.abspath(pdf_path)}"
    result = converter.convert(pdf_path)
    return result


def process_pdf_documents(pdf_dir):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ PDF-–¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏.
    
    Args:
        pdf_dir: –ø—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å PDF-—Ñ–∞–π–ª–∞–º–∏
        
    Returns:
        –°–ø–∏—Å–æ–∫ —á–∞–Ω–∫–æ–≤ –∏–∑ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    """
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ PDF —Ñ–∞–π–ª—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    pdf_files = glob.glob(os.path.join(pdf_dir, "*.pdf"))
    
    if not pdf_files:
        print(f"–í –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ {pdf_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ PDF-—Ñ–∞–π–ª–æ–≤")
        return []
    
    all_chunks = []
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π PDF —Ñ–∞–π–ª
    for pdf_file in pdf_files:
        print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {pdf_file}")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PDF –≤ —Ñ–æ—Ä–º–∞—Ç docling
        result = convert_pdf_to_document(pdf_file)
        
        # –°–æ–∑–¥–∞–µ–º —á–∞–Ω–∫–µ—Ä
        chunker = HybridChunker(
            tokenizer=tokenizer,
            max_tokens=MAX_TOKENS,
            merge_peers=True,  # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–æ—Å–µ–¥–Ω–∏–µ —á–∞–Ω–∫–∏ –ø—Ä–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
        )
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –Ω–∞ —á–∞–Ω–∫–∏
        chunk_iter = chunker.chunk(dl_doc=result.document)
        chunks = list(chunk_iter)
        
        print(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {pdf_file}")
        all_chunks.extend(chunks)
    
    print(f"–í—Å–µ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ {len(all_chunks)} —á–∞–Ω–∫–æ–≤ –∏–∑ {len(pdf_files)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    return all_chunks

@retry(
    stop=stop_after_attempt(5),
    wait=wait_exponential(multiplier=1, min=1, max=60),
    retry=retry_if_exception_type((openai.RateLimitError, openai.APIError, openai.APIConnectionError))
)
def create_embedding(text):
    """
    –°–æ–∑–¥–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —Ç–µ–∫—Å—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º OpenAI API.
    
    –§—É–Ω–∫—Ü–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä retry –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–≤—Ç–æ—Ä–∞
    –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö API (rate limits, timeout –∏ —Ç.–¥.)
    
    Args:
        text: —Ç–µ–∫—Å—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
        
    Returns:
        –í–µ–∫—Ç–æ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
    """
    response = client.embeddings.create(
        model="text-embedding-3-large",
        input=text,
        dimensions=1536
    )
    return response.data[0].embedding

def create_or_connect_db(db_path="data/lancedb"):
    """
    –°–æ–∑–¥–∞–µ—Ç –∏–ª–∏ –ø–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö LanceDB.
    
    Args:
        db_path: –ø—É—Ç—å –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        
    Returns:
        –û–±—ä–µ–∫—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö
    """
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    os.makedirs(os.path.dirname(db_path), exist_ok=True)
    
    # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
    return lancedb.connect(db_path)


def create_and_fill_table(db, chunks, table_name="pdf_chunks"):
    """
    –°–æ–∑–¥–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—É –≤ LanceDB –∏ –∑–∞–ø–æ–ª–Ω—è–µ—Ç –µ–µ —á–∞–Ω–∫–∞–º–∏ —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏.
    
    Args:
        db: —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö
        chunks: —Å–ø–∏—Å–æ–∫ —á–∞–Ω–∫–æ–≤ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ —Ç–∞–±–ª–∏—Ü—É
        table_name: –∏–º—è —Å–æ–∑–¥–∞–≤–∞–µ–º–æ–π —Ç–∞–±–ª–∏—Ü—ã
        
    Returns:
        –û–±—ä–µ–∫—Ç —Ç–∞–±–ª–∏—Ü—ã LanceDB
    """
    print(f"üß† –ù–∞—á–∏–Ω–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è {len(chunks)} —á–∞–Ω–∫–æ–≤...")
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ö–µ–º—É —Ç–∞–±–ª–∏—Ü—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º PyArrow
    print("üìã –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ö–µ–º—É —Ç–∞–±–ª–∏—Ü—ã...")
    schema = pa.schema([
        pa.field("text", pa.string()),                      # –¢–µ–∫—Å—Ç —á–∞–Ω–∫–∞
        pa.field("vector", pa.list_(pa.float32(), 1536)),   # –≠–º–±–µ–¥–¥–∏–Ω–≥ (–≤–µ–∫—Ç–æ—Ä)
        pa.field("doc_name", pa.string()),                  # –ò–º—è –¥–æ–∫—É–º–µ–Ω—Ç–∞
        pa.field("chunk_id", pa.int32())                    # ID —á–∞–Ω–∫–∞
    ])
    
    # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
    print("üèóÔ∏è –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö...")
    table = db.create_table(table_name, schema=schema, mode="overwrite")
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —á–∞–Ω–∫–∏ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ —Ç–∞–±–ª–∏—Ü—É
    print("üîÑ –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —á–∞–Ω–∫–∏ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è...")
    processed_chunks = []
    
    for i, chunk in enumerate(chunks):
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —á–∞–Ω–∫–∞
        if hasattr(chunk, "text"):
            chunk_text = chunk.text
        else:
            chunk_text = str(chunk)
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–º—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º
        doc_name = "unknown"
        if hasattr(chunk, "metadata") and isinstance(chunk.metadata, dict) and "file_name" in chunk.metadata:
            doc_name = chunk.metadata["file_name"]
        else:
            doc_name = f"doc_{i // 2}"  # –ü—Ä–æ—Å—Ç–∞—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –µ—Å–ª–∏ –Ω–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        
        processed_chunks.append({
            "text": chunk_text,
            "doc_name": doc_name,
            "chunk_id": i
        })
    

    progress = widgets.IntProgress(
        value=0,
        min=0,
        max=len(processed_chunks),
        description='–ü—Ä–æ–≥—Ä–µ—Å—Å:',
        bar_style='info',
        orientation='horizontal'
    )
    display(progress)
    
    # –°—á–µ—Ç—á–∏–∫ —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
    successful_chunks = 0
    
    # –°–æ–∑–¥–∞–µ–º –∏ –¥–æ–±–∞–≤–ª—è–µ–º –∫–∞–∂–¥—ã–π —á–∞–Ω–∫ –æ—Ç–¥–µ–ª—å–Ω–æ
    print(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ —Ç–∞–±–ª–∏—Ü—É ({len(processed_chunks)} —á–∞–Ω–∫–æ–≤)...")
    for i, chunk in enumerate(processed_chunks):
        chunk_preview = chunk["text"][:30].replace("\n", " ") + "..."
        print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞–Ω–∫–∞ {i+1}/{len(processed_chunks)}: '{chunk_preview}'")
        
        try:
            # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —á–∞–Ω–∫–∞
            print(f"   üßÆ –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞...")
            vector = create_embedding(chunk["text"])
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤–µ–∫—Ç–æ—Ä –∫ –¥–∞–Ω–Ω—ã–º —á–∞–Ω–∫–∞
            chunk_to_add = chunk.copy()
            chunk_to_add["vector"] = vector
            
            # –î–æ–±–∞–≤–ª—è–µ–º —á–∞–Ω–∫ –≤ —Ç–∞–±–ª–∏—Ü—É
            print(f"   üíæ –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ —Ç–∞–±–ª–∏—Ü—É...")
            table.add([chunk_to_add])
            
            print(f"‚úÖ –ß–∞–Ω–∫ {i+1} —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∏ –¥–æ–±–∞–≤–ª–µ–Ω –≤ —Ç–∞–±–ª–∏—Ü—É.")
            successful_chunks += 1
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
            progress.value = i + 1
            
            # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è rate limits
            time.sleep(random.uniform(0.5, 1.5))
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —á–∞–Ω–∫–∞ {i+1}: {str(e)}")
            print(f"   –¢–∏–ø –æ—à–∏–±–∫–∏: {type(e).__name__}")
    
    print(f"\nüéâ –ì–æ—Ç–æ–≤–æ! {successful_chunks} –∏–∑ {len(processed_chunks)} —á–∞–Ω–∫–æ–≤ —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ —Ç–∞–±–ª–∏—Ü—É {table_name}")
    
    return table

def search_in_table(query_text, table, limit=3):
    """
    –ü–æ–∏—Å–∫ –≤ —Ç–∞–±–ª–∏—Ü–µ LanceDB –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –∑–∞–ø—Ä–æ—Å—É.
    
    –≠—Ç–æ—Ç –º–µ—Ç–æ–¥ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:
    1. –°–æ–∑–¥–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ 
    2. –í—ã–ø–æ–ª–Ω—è–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π
    3. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    
    Args:
        query_text (str): –¢–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        table: –¢–∞–±–ª–∏—Ü–∞ LanceDB –¥–ª—è –ø–æ–∏—Å–∫–∞
        limit (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        
    Returns:
        pandas.DataFrame: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞
    """
    print(f"üîç –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å: '{query_text}'")
    
    try:
        # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
        print("üß† –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞...")
        query_embedding = create_embedding(query_text)
        print(f"‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥ —Å–æ–∑–¥–∞–Ω, —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {len(query_embedding)}")
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ —ç–º–±–µ–¥–¥–∏–Ω–≥—É
        print(f"üîé –ò—â–µ–º {limit} –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤...")
        results = table.search(query_embedding).limit(limit).to_pandas()
        
        print(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        return results
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {str(e)}")
        raise


def display_search_results(results):
    """
    –û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –≤ –∫—Ä–∞—Å–∏–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ.
    
    Args:
        results (pandas.DataFrame): –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –∏–∑ search_in_table
    """
    if results is None or len(results) == 0:
        print("‚ùå –ü–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
        return
    
    print(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
    
    for i, row in results.iterrows():
        doc_name = row.get("doc_name", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç")
        chunk_id = row.get("chunk_id", i)
        distance = row.get("_distance", "–Ω/–¥")
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        text_preview = row['text'][:300].replace("\n", "<br>")
        
        # –°–æ–∑–¥–∞–µ–º HTML –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        text = f"""
            –†–µ–∑—É–ª—å—Ç–∞—Ç #{i+1} (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {distance:.4f})\n
            –ò—Å—Ç–æ—á–Ω–∏–∫:   {doc_name}\n
            ID —á–∞–Ω–∫–∞:   {chunk_id}\n
            –¢–µ–∫—Å—Ç:      {text_preview}... \n
        """
        print(text)


    """
–≠—Ç–æ—Ç –±–ª–æ–∫ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å 
–ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏: –æ—Ç –∑–∞–≥—Ä—É–∑–∫–∏ PDF –¥–æ —Å–æ–∑–¥–∞–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.
"""

def run_pipeline(pdf_dir=None, db_path=None, table_name=None):
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏: –æ—Ç –∑–∞–≥—Ä—É–∑–∫–∏ PDF –¥–æ —Å–æ–∑–¥–∞–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.
    
    Args:
        pdf_dir: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å PDF-—Ñ–∞–π–ª–∞–º–∏ 
        db_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        table_name: –ò–º—è —Ç–∞–±–ª–∏—Ü—ã –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
    """
    # –ï—Å–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–µ —É–∫–∞–∑–∞–Ω—ã, –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –∏—Ö
    if not pdf_dir:
        pdf_dir = input("–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å PDF-—Ñ–∞–π–ª–∞–º–∏: ")
    if not db_path:
        db_path = input("–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö [data/lancedb]: ") or "data/lancedb"
    if not table_name:
        table_name = input("–í–≤–µ–¥–∏—Ç–µ –∏–º—è —Ç–∞–±–ª–∏—Ü—ã –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö [pdf_docs]: ") or "pdf_docs"
    
    print("\n" + "="*50)
    print(f"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É PDF –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    print(f"üìÇ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å PDF: {pdf_dir}")
    print(f"üíæ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {db_path}")
    print(f"üìã –ò–º—è —Ç–∞–±–ª–∏—Ü—ã: {table_name}")
    print("="*50 + "\n")
    
    # –®–∞–≥ 1: –û–±—Ä–∞–±–æ—Ç–∫–∞ PDF-–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    chunks = process_pdf_documents(pdf_dir)

    if not chunks:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —á–∞–Ω–∫–∏ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        return False
    
    # –®–∞–≥ 2: –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã LanceDB
    print("\n" + "="*50)
    print("üíæ –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
    print("="*50)
    
    db = create_or_connect_db(db_path)
    print("‚úÖ –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –ë–î —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
    table = create_and_fill_table(db, chunks, table_name)
    
    # –®–∞–≥ 3: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö
    print("\n" + "="*50)
    print("üéâ –ò—Ç–æ–≥–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
    print(f"üìÇ –°–æ–∑–¥–∞–Ω–∞ –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {db_path}")
    print(f"üìã –°–æ–∑–¥–∞–Ω–∞ —Ç–∞–±–ª–∏—Ü–∞: {table_name}")
    print(f"üìä –í—Å–µ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ —á–∞–Ω–∫–æ–≤: {len(chunks)}")
    print("="*50)
    
    return True

"""
–≠—Ç–æ—Ç –±–ª–æ–∫ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ –≤—ã–ø–æ–ª–Ω—è—Ç—å –ø–æ–∏—Å–∫ –≤ —Å–æ–∑–¥–∞–Ω–Ω–æ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.
"""

def interactive_search(db_path=None, table_name=None):
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ —Å–æ–∑–¥–∞–Ω–Ω–æ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.
    
    Args:
        db_path: –ü—É—Ç—å –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        table_name: –ò–º—è —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è –ø–æ–∏—Å–∫–∞
    """
    # –ï—Å–ª–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–µ —É–∫–∞–∑–∞–Ω—ã, –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –∏—Ö
    if not db_path:
        db_path = input("–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö [data/lancedb]: ") or "data/lancedb"
    if not table_name:
        table_name = input("–í–≤–µ–¥–∏—Ç–µ –∏–º—è —Ç–∞–±–ª–∏—Ü—ã –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö [pdf_docs]: ") or "pdf_docs"
    
    try:
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        db = lancedb.connect(db_path)
        
        # –û—Ç–∫—Ä—ã–≤–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
        table = db.open_table(table_name)
        
        # –ü–æ–ª–µ –≤–≤–æ–¥–∞ –∑–∞–ø—Ä–æ—Å–∞
        query_input = widgets.Text(
            value='',
            placeholder='–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å...',
            description='–ó–∞–ø—Ä–æ—Å:',
            disabled=False,
            layout=widgets.Layout(width='80%')
        )
        
        # –°–ª–∞–π–¥–µ—Ä –¥–ª—è –≤—ã–±–æ—Ä–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        limit_slider = widgets.IntSlider(
            value=3,
            min=1,
            max=10,
            step=1,
            description='–ö–æ–ª-–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:',
            disabled=False,
            continuous_update=False,
            orientation='horizontal',
            readout=True,
            readout_format='d'
        )
        
        # –ö–Ω–æ–ø–∫–∞ –ø–æ–∏—Å–∫–∞
        search_button = widgets.Button(
            description='–ü–æ–∏—Å–∫',
            button_style='success',
            tooltip='–ù–∞–∂–º–∏—Ç–µ –¥–ª—è –ø–æ–∏—Å–∫–∞',
            icon='search'
        )
        
        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        output = widgets.Output()
        
        # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–∞–∂–∞—Ç–∏—è –∫–Ω–æ–ø–∫–∏
        def on_search_button_click(b):
            query = query_input.value
            limit = limit_slider.value
            
            if not query:
                with output:
                    clear_output()
                    display(HTML("<p style='color:red'>‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å</p>"))
                return
            
            with output:
                clear_output()
                print(f"üîç –ü–æ–∏—Å–∫ –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{query}'")
                results = search_in_table(query, table, limit)
                display_search_results(results)
        
        # –ü—Ä–∏–≤—è–∑—ã–≤–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –∫ –∫–Ω–æ–ø–∫–µ
        search_button.on_click(on_search_button_click)
        
        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
        display(widgets.VBox([
            widgets.HBox([query_input, search_button]),
            limit_slider,
            output
        ]))
    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–∏ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")

PDF_DIR = "../bank_data_output/pdf"
DB_PATH = "./lancedb"
TABLE_NAME = "pdf_docs" 

# –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
success = run_pipeline(PDF_DIR, DB_PATH, TABLE_NAME)

# –ï—Å–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —É—Å–ø–µ—à–Ω–∞, –∑–∞–ø—É—Å–∫–∞–µ–º –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫
if success:
    # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
    db = lancedb.connect(DB_PATH)
        
    # –û—Ç–∫—Ä—ã–≤–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
    table = db.open_table(TABLE_NAME)
    question = ""
    while(question!="exit"):
        question = input("Enter your question or 'exit' to quit: ")
        if question != "exit":
            results = search_in_table(question, table, 3)
            display_search_results(results)
    